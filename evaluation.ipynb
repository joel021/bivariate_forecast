{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.cluster_hundler import *\n",
    "from package.miscellaneous import *\n",
    "from package.model_hundler import *\n",
    "from package.process_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_norm(norm_df, params):\n",
    "    df = norm_df.copy()\n",
    "\n",
    "    df.loc[:, params['x_col']] = df[params['x_col']]*params['x_max']\n",
    "    df.loc[:, params['y_col']] = df[params['y_col']]*params['y_max']\n",
    "\n",
    "    df.loc[:, 'z'] = df['z']*params['z_max'][int(df.iloc[0]['group'])]\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_df(data_df, params, z_col, title, plot_limits = True, w = 20, h = 20, dpi = 60):\n",
    "\n",
    "    figure(figsize=(w,h),dpi=dpi)\n",
    "    ax = plt.axes(projection ='3d')\n",
    "\n",
    "    ax.scatter(data_df[params['x_col']], data_df[params['y_col']], data_df[z_col], c = data_df[z_col])\n",
    "    ax.set_ylabel(params['y_col'])\n",
    "    ax.set_xlabel(params['x_col'])\n",
    "    ax.set_zlabel(z_col)\n",
    "    \n",
    "##---------- #Plot limitations -----------------\n",
    "    if plot_limits:\n",
    "        d_p = data_df[data_df[params['x_col']] == params['x_k']]\n",
    "        z_p = (d_p[d_p[params['y_col']] == params['y_k']]).iloc[0][z_col]\n",
    "        \n",
    "        #vertical line at x = x_k, y = y_k\n",
    "        ax.plot(np.ones(int(z_p)+1)*params['x_k'],\n",
    "                np.ones(int(z_p)+1)*params['y_k'],\n",
    "                np.arange(0, int(z_p)+1, 1), 'k--', alpha=1, linewidth=2.5)\n",
    "        \n",
    "        #horizontal line at: x = x_k, z = 0\n",
    "        cy = int(params['y_k'] / params['y_step'] + 1)\n",
    "        ax.plot(np.ones(cy)*params['x_k'],\n",
    "                np.arange(0,params['y_k']+params['y_step'],params['y_step']),\n",
    "                np.ones(cy)*0,'k--',alpha=1, linewidth=2.5)\n",
    "\n",
    "        #horizontal line at: y = y_k, z = 0\n",
    "        cx = int(params['x_k'] / params['x_step'] + 1)\n",
    "        ax.plot(np.arange(0,params['x_k']+params['x_step'],params['x_step']),\n",
    "                np.ones(cx)*params['y_k'],\n",
    "                np.ones(cx)*0,\n",
    "                'k--',alpha=1, linewidth=2.5)\n",
    "\n",
    "        #horizontal line at: x = x_k, z = z_p\n",
    "        cy = int(params['y_k'] / params['y_step'] + 1)\n",
    "        ax.plot(np.ones(cy)*params['x_k'],\n",
    "                np.arange(0,params['y_k']+params['y_step'],params['y_step']),\n",
    "                np.ones(cy)*z_p,'k--',alpha=1, linewidth=2.5)\n",
    "\n",
    "        #horizontal line at: y = y_k, z = z_p\n",
    "        cx = int(params['x_k'] / params['x_step'] + 1)\n",
    "        ax.plot(np.arange(0,params['x_k']+params['x_step'],params['x_step']),\n",
    "                np.ones(cx)*params['y_k'],\n",
    "                np.ones(cx)*z_p,\n",
    "                'k--',alpha=1, linewidth=2.5)\n",
    "        #-------------------------------------------------\n",
    "\n",
    "    # syntax for plotting\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./models/fit_wtfilters_SA_NA_c15/\"\n",
    "sub_path = \"val_sub_models_15\"\n",
    "\n",
    "params = dict(json.loads(open(path+\"/\"+sub_path+\"/model_params.json\", \"r\").read()))\n",
    "database = load_db(path+\"/database.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_norm_submodels_df = pd.read_csv(\"./data/fit_norm_submodels_df.csv\")\n",
    "val_norm_submodels_df = pd.read_csv(\"./data/val_norm_submodels_df.csv\")\n",
    "fit_val_norm_data = pd.concat([fit_norm_submodels_df, val_norm_submodels_df]).sort_values(by=['filter_', params['x_col'], params['y_col']])\n",
    "fit_val_data = pd.read_csv(\"./data/fit_val_data_submodels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_val_g = fit_val_data.groupby(by=\"filter_\")\n",
    "fit_norm_g = fit_norm_submodels_df.groupby(by='filter_')\n",
    "fit_val_max = fit_val_g.max()\n",
    "\n",
    "database['data_arr'] = {k: v for k, v in sorted(database['data_arr'].items(), key=lambda item: item[0])}\n",
    "\n",
    "describe_results = []\n",
    "\n",
    "threads = []\n",
    "\n",
    "l = list(glob.glob(path+\"/\"+sub_path+\"/*.h5\"))\n",
    "ll = np.array([ v.replace(\"//\",\"/\").replace('\\\\', '/').replace(\".h5\",\"\").split(\"/\") for v in l])[:,-1]\n",
    "\n",
    "filters = np.intersect1d(list(fit_norm_g.indices.keys()), ll)\n",
    "\n",
    "for filter_ in filters:\n",
    "    fit_val_f = fit_val_g.get_group(filter_) #original data non normalized\n",
    "\n",
    "    sub_model = tf.keras.models.load_model(path+\"/\"+sub_path+\"/\"+filter_+\".h5\")\n",
    "    group = int(fit_norm_g.get_group(filter_).iloc[0]['group']) #get the group used to fit the model\n",
    "    df_pred = predict_regression(sub_model, database, params, group) #inference already in real values\n",
    "    df_pred = df_pred[df_pred[params['x_col']] <= fit_val_max.loc[filter_,params['x_col']]]\n",
    "    df_pred = df_pred[df_pred[params['y_col']] <= fit_val_max.loc[filter_,params['y_col']]]\n",
    "\n",
    "    describe_results.append({\n",
    "        \"filter_\": filter_,\n",
    "        \"group\": group,\n",
    "        \"overall_mae\": mean_absolute_error(fit_val_f.z, df_pred.z_pred)\n",
    "    })\n",
    "\n",
    "describe_results_df = pd.DataFrame(describe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cutted_compare = cut_flattening_filters(df=fit_val_data, params=params, filter_c='filter_', dz_per=0.25)\n",
    "\n",
    "fit_val_g = fit_val_data.groupby(by=\"filter_\")\n",
    "fit_norm_g = fit_norm_submodels_df.groupby(by='filter_')\n",
    "describe_g = describe_results_df.groupby(by=\"filter_\")\n",
    "\n",
    "database['data_arr'] = {k: v for k, v in sorted(database['data_arr'].items(), key=lambda item: item[0])}\n",
    "\n",
    "for filter_ in filters:\n",
    "\n",
    "    #Plot original data\n",
    "    fit_val_f = fit_val_g.get_group(filter_)\n",
    "    plot_df(data_df=fit_val_f, params = params, z_col = 'z', title=\"original: \"+filter_, plot_limits =True, w = 10, h = 10, dpi=60)\n",
    "\n",
    "    #make prediction\n",
    "    sub_model = tf.keras.models.load_model(path+\"/\"+sub_path+\"/\"+filter_+\".h5\")\n",
    "    group = int(fit_norm_g.get_group(filter_).iloc[0]['group']) #get the group used to fit the model\n",
    "\n",
    "    df_pred = predict_regression(sub_model, database, params, group)\n",
    "    plot_df(data_df=df_pred, params = params, z_col = 'z_pred', title=\"prediction: \"+filter_+\" over_all error: \"+str(describe_g.get_group(filter_).iloc[0]['overall_mae']), w = 10, h = 10, dpi=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f2ac25b4a6d870602abfa5d74e7d6f1ae274ba9e86645830384575c0e5c89f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
