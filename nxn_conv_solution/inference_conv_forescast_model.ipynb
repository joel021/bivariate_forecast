{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.process_data import *\n",
    "from package.cluster_hundler import *\n",
    "from package.model_hundler import *\n",
    "from package.miscellaneous import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_to_generator(df, filter_c_name, params):\n",
    "    \"\"\"Generate the data to fit cluster. The shape of output is (length, 3)\n",
    "\n",
    "    @df: Dataframe accumulated and not normalized. Must have \"z\" column\n",
    "    @filter_c_name: Filter column name. Usually as \"filter_\"\n",
    "    @params: dict with x column name (odometer), y column name (tis) and so on.\n",
    "        params['length']: length of each sample. The result is a list of samples with this length\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    df_f = df[df[params['x_col']] <= params['x_k']]\n",
    "    df_f = df_f[df_f[params['y_col']] <= params['y_k']]\n",
    "\n",
    "    df_g = df.sort_values([filter_c_name, params['x_col'], params['y_col']]).groupby(by=filter_c_name)\n",
    "    df_f_g = df_f.sort_values([filter_c_name, params['x_col'], params['y_col']]).groupby(by=filter_c_name)\n",
    "\n",
    "    z_max = 0\n",
    "\n",
    "    x_c = int(params['x_k'] / params['x_step'])+1\n",
    "    y_c = int(params['y_k'] / params['y_step'])+1\n",
    "\n",
    "    x_t = int(params['x_max'] / params['x_step'])+1\n",
    "    y_t = int(params['y_max'] / params['y_step'])+1\n",
    "\n",
    "    for filter_ in df_g.indices:\n",
    "        \n",
    "        #X:\n",
    "        f_df = df_f_g.get_group(filter_)\n",
    "        X.append(np.array(f_df['z']).reshape((x_c, y_c)))\n",
    "\n",
    "        #y:\n",
    "        y.append(np.array(df_g.get_group(filter_)['z']).reshape((x_t, y_t)))\n",
    "\n",
    "        z_max = max(z_max, f_df['z'].max())\n",
    "\n",
    "    params['z_max']['general'] = z_max\n",
    "\n",
    "    return np.array(X) / z_max, np.array(y) / z_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate the second architecture of the regressor model\n",
    "params = dict({\"x_col\": \"milge\",\n",
    "                \"x_max\": 70_000,\n",
    "                \"x_step\": 2_000,\n",
    "                \"y_col\": \"tis_wsd\",\n",
    "                \"key\": \"vin_cd\",\n",
    "                \"y_max\": 70,\n",
    "                \"y_step\": 1,\n",
    "                \"y_k\": 21, #number of tis to be considered as input to cluster\n",
    "                \"x_k\": 30_000, #number of milge to be considered as input to cluster\n",
    "                \"z_max\": dict(), #group1: value1, group2: value2, group3: value3\n",
    "                \"k\": 4\n",
    "                })\n",
    "\n",
    "claims_df = pd.read_csv(\"./data/test_claims.tsv\", sep='\\t')\n",
    "prod_df = pd.read_csv(\"./data/test_prod.tsv\", sep='\\t')\n",
    "\n",
    "#TODO: The data used is already constructed and normalized.\n",
    "#Build History Data\n",
    "print(\"Built History Data\")\n",
    "history_data = build_data(  clm_list=claims_df, \n",
    "                            prod_list = prod_df, \n",
    "                            cols_group = [\"veh_line_cd\",\"eng_cd\",\"mdl_yr\",\"prt_num_causl_base_cd\"], \n",
    "                            params=params)\n",
    "\n",
    "print(\"Remove Outliers\")\n",
    "history_data = sel_dist_window(df = history_data, #TODO: add insert noise function\n",
    "                                f_col = \"filter_\",\n",
    "                                z_max = [2,40], #z_max: base and top\n",
    "                                params = params,\n",
    "                                max_filters=500)\n",
    "\n",
    "\n",
    "X,y =  build_data_to_generator(df = history_data,\n",
    "                                        filter_c_name = \"filter_\",\n",
    "                                        params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/base_conv.h5\")\n",
    "z_pred = model.predict(np.array([X[0]]))\n",
    "z_2D = z_pred[0].reshape(36,71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 14\n",
    "h = 9\n",
    "\n",
    "X_input = create_X(params, 0)\n",
    "df_arr = X_input[[params['x_col'], params['y_col']]].sort_values(by=[params['x_col'], params['y_col']]).values\n",
    "x_p = int(params['x_max'] / params['x_step'])+1\n",
    "y_p = int(params['y_max'] / params['y_step'])+1\n",
    "\n",
    "x_2D = df_arr[:,0].reshape((x_p, y_p))\n",
    "y_2D = df_arr[:,1].reshape((x_p, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input.loc[:,'z'] = z_2D.reshape(x_p*y_p)\n",
    "plot_df(data_df=X_input, x_col = params['x_col'], y_col=params['y_col'], z_col = \"z\", title='test',  w = 20, h = 20, dpi = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure(figsize =(w, h))\n",
    "ax = plt.axes(projection ='3d')\n",
    "\n",
    "ax.plot_surface(df_arr[params['x_col']], y_2D, z_2D)\n",
    "ax.set_title(\"title\")\n",
    "ax.set_ylabel(params['y_col'])\n",
    "ax.set_xlabel(params['x_col'])\n",
    "ax.set_zlabel(\"z\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To do:\n",
    "\"\"\"\n",
    "1. Add inference in unknow data\n",
    "2. Add noise to fit data\n",
    "3. Add postprocessing\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f2ac25b4a6d870602abfa5d74e7d6f1ae274ba9e86645830384575c0e5c89f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
