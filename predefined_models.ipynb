{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from glob import glob\n",
    "from scipy.special import erf\n",
    "from scipy.optimize import curve_fit\n",
    "import json\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from package.miscellaneous import export_params, load_db, plot_df, nbits\n",
    "from package.process_data import norm_encode_bycluster, cut_flattening_filters, slice_df\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.acc_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath = \"fit_wtfilters_SA_NA_c\"\n",
    "database = load_db(\"./models/\"+subpath+\"/database.json\")\n",
    "params = json.loads(open(\"./models/\"+subpath+\"/base_model_params.json\", \"r\").read())\n",
    "params['x_c'] = 25_000\n",
    "params['y_c'] = 25\n",
    "\n",
    "export_params(\"./models/\"+subpath+\"/submodels_params.json\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_val_df = pd.read_csv(\"./data/fit_val_data_submodels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cutted_df = cut_flattening_filters(df=fit_val_df, params=params, filter_c='filter_', dz_per=0.25)\n",
    "\n",
    "fit_val_norm_df = norm_encode_bycluster(df = top_cutted_df,\n",
    "                                        database = database,\n",
    "                                        params = params,\n",
    "                                        filter_c_name = \"filter_\",\n",
    "                                        norm_xy = False)\n",
    "\n",
    "print(\"Slice\")\n",
    "fit_norm_df, val_norm_df = slice_df(df = fit_val_norm_df,\n",
    "                                    params = params,\n",
    "                                    filter_col = \"filter_\",\n",
    "                                    y_min = params['y_c']+3,\n",
    "                                    isnorm=False\n",
    "                                    )\n",
    "\n",
    "print(\"Shape of fit_norm_df: \", str(np.shape(fit_norm_df)))\n",
    "print(\"Shape of val_norm_df: \", str(np.shape(val_norm_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare before fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_val_g = fit_val_df.groupby(by=\"filter_\")\n",
    "fit_val_c_g = top_cutted_df.groupby(by=\"filter_\")\n",
    "\n",
    "filters = list(fit_val_g.indices.keys())\n",
    "\n",
    "i = 5\n",
    "plot_df(fit_val_g.get_group(filters[i]),\n",
    "        x_col=params['x_col'],\n",
    "        y_col=params['y_col'],\n",
    "        z_col = \"z\", title=\"t\",\n",
    "        w = 10,\n",
    "        h = 6)\n",
    "\n",
    "plot_df(fit_val_c_g.get_group(filters[i]),\n",
    "        x_col=params['x_col'],\n",
    "        y_col=params['y_col'],\n",
    "        z_col = \"z\", title=\"t\",\n",
    "        w = 10,\n",
    "        h = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xmodel_prediction(func, model_args, params):\n",
    "    \"\"\"This function return the z values predicted to 0 <= x <= x_max and 0 <= y <= y_max\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe = []\n",
    "\n",
    "    y_arr = np.arange(0, params['y_max'] + params['y_step'], params['y_step']) #get unique values to y\n",
    "    x_arr = np.arange(0, params['x_max'] + params['x_step'], params['x_step'])\n",
    "\n",
    "    ones = np.ones(len(y_arr)) #aux arr to make broadcast\n",
    "\n",
    "    for x in x_arr: #to each unique value of x\n",
    "        df_i = pd.DataFrame({params['y_col']: y_arr,\n",
    "                            params['x_col']: ones*x, #broadcast\n",
    "                            \"z\": func(y_arr/params['y_max'], *model_args[x])})\n",
    "        dataframe.append(df_i)\n",
    "\n",
    "    dataframe_df = pd.concat(dataframe)\n",
    "    dataframe_df = dataframe_df.sort_values(by=[params['x_col'], params['y_col']])\n",
    "\n",
    "    return dataframe_df\n",
    "    \n",
    "def ymodel_prediction(func, model_args, params):\n",
    "    \"\"\"This function return the z values predicted to 0 <= x <= x_max and 0 <= y <= y_max\n",
    "    \"\"\"\n",
    "    dataframe = []\n",
    "\n",
    "    y_arr = np.arange(0, params['y_max'] + params['y_step'], params['y_step']) #get unique values to y\n",
    "    x_arr = np.arange(0, params['x_max'] + params['x_step'], params['x_step']) #get unique values to x\n",
    "    ones = np.ones(len(x_arr)) #aux arr to make broadcast\n",
    "    \n",
    "    for y in y_arr: #to each unique value of x\n",
    "        df_i = pd.DataFrame({params['x_col']: x_arr,\n",
    "                            params['y_col']: ones*y, #broadcast\n",
    "                            \"z\": func(x_arr/params['y_max'], *model_args[y])})\n",
    "        dataframe.append(df_i)\n",
    "\n",
    "    dataframe_df = pd.concat(dataframe)\n",
    "    dataframe_df = dataframe_df.sort_values(by=[params['x_col'], params['y_col']])\n",
    "\n",
    "    return dataframe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_submodels(model_func, fit_znorm_df, filter_col, params):\n",
    "    \"\"\"Build the submodels to predict z to 0 <= x <= x_max and 0 <= y <= y_max.\n",
    "    @fit_znorm_df: only z can be normalized.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"building yk models\")\n",
    "    p_y = params.copy()\n",
    "    p_y['x_col'] = params['y_col']\n",
    "    p_y['y_col'] = params['x_col']\n",
    "    p_y['y_max'] = params['x_max']\n",
    "    p_y['x_max'] = params['y_max']\n",
    "    yk_acc_models = build_models(model_func, fit_znorm_df, filter_col, p_y) #return models with keys (in y values) \n",
    "    \n",
    "    #--------- TODO predict to x > x_k TODO ---------------------------------\n",
    "    print(\"Predicting from 0 <= x <= x_max\")\n",
    "    p = params.copy()\n",
    "    p_y['y_max'] = params['y_k'] #limit y_max because the model haven't keys to y > y_k\n",
    "\n",
    "    yk_pred_df = [] #complete y first\n",
    "\n",
    "    for filter_ in fit_znorm_df.groupby(by=filter_col).indices.keys(): #to each x, predict to 0 <= y <= y_max\n",
    "        pred_df_filter = ymodel_prediction(func = model_func, model_args = yk_acc_models[filter_], params = p_y) #Make prediction to current data of a filter\n",
    "        pred_df_filter.loc[:,\"filter_\"] = filter_\n",
    "        yk_pred_df.append(pred_df_filter)\n",
    "        \n",
    "    yk_pred_df = pd.DataFrame(yk_pred_df)\n",
    "    yk_pred_df = yk_pred_df[yk_pred_df[params['x_col']] > params['x_k']]#persist only x > x_k\n",
    "\n",
    "    fit_znorm_df = pd.concat([fit_znorm_df, yk_pred_df])\n",
    "\n",
    "    print(\"building xmodels\")\n",
    "    return build_models(model_func, fit_znorm_df, filter_col, params) #do fit to 0 <= x <= x_max as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dist = CommonDistribution()\n",
    "model_func = common_dist.CD_logo_normal\n",
    "\n",
    "acc_models = build_submodels(model_func = model_func,\n",
    "                            fit_znorm_df = fit_val_norm_df, \n",
    "                            filter_col = \"filter_\",\n",
    "                            params = params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in acc_models.keys():\n",
    "\n",
    "    if type(acc_models[k]) == type(dict()):\n",
    "\n",
    "        for k2 in acc_models[k].keys():\n",
    "            if type(acc_models[k][k2]) == type(np.array([])):\n",
    "                acc_models[k][k2] = acc_models[k][k2].tolist()\n",
    "\n",
    "export_params(\"./models/\"+subpath+\"/\"+model_func.__name__+\".json\", acc_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = list(fit_val_norm_df.groupby(by=\"filter_\").indices.keys())\n",
    "\n",
    "func = acc_models[\"func\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get over all error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_error(acc_models, database, norm_df, filter_col):\n",
    "    \"\"\"\n",
    "    @acc_models:\n",
    "    @database: dictionary with the database used to define the differents groups of the dataset\n",
    "    @norm_df: the dataset to be used to compare\n",
    "    @filter_col:\n",
    "    \"\"\"\n",
    "    #prepare the data to iterate\n",
    "    g_df = norm_df.groupby(by=filter_col)\n",
    "    filters = list(g_df.indices.keys())\n",
    "\n",
    "    common_dist = CommonDistribution() #Instance with the supported distributions\n",
    "    model_func = getattr(common_dist, acc_models['func']) #get the function by name as string\n",
    "    \n",
    "    max_df = g_df.max()\n",
    "\n",
    "    over_all_error = []\n",
    "    p = acc_models[\"params\"].copy()\n",
    "    for filter_ in filters:\n",
    "        print(filter_)\n",
    "        p['x_max'] = max_df.loc[filter_, p['x_col']] * p['x_max'] \n",
    "        p['y_max'] = max_df.loc[filter_, p['y_col']] * p['y_max']\n",
    "\n",
    "        pred_df_filter = xmodel_prediction(model_func, acc_models[filter_], p) #Make prediction to current data of a filter\n",
    "        \n",
    "        df_filter = g_df.get_group(filter_) #get the dataframe of this filter\n",
    "\n",
    "        #Revert normalization of the all data\n",
    "        z_max = database['z_max'][int(acc_models[filter_]['group'])]\n",
    "        pred_df_filter.loc[:,'z'] = pred_df_filter['z']*z_max\n",
    "        df_filter.loc[:,'z'] = df_filter['z']*z_max\n",
    "\n",
    "        over_all_error.append({\n",
    "            \"filter_\": filter_,\n",
    "            \"mae_error\": mean_absolute_error(df_filter['z'],pred_df_filter['z'])\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(over_all_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_summary_df = overall_error(acc_models, database, fit_val_df, \"filter_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = fit_val_norm_df.groupby(by=\"filter_\")\n",
    "filters = list(g_df.indices.keys())\n",
    "filter_ = filters[1]\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "df_filter = g_df.get_group(filter_) #get the dataframe of this filter\n",
    "y_arr = np.arange(0, params['y_max'] + params['y_step'], params['y_step']) #get unique values to y\n",
    "ones = np.ones(len(y_arr)) #aux arr to make broadcast\n",
    "\n",
    "for x in df_filter[params['x_col']].unique(): #to each unique value of x\n",
    "    df_i = pd.DataFrame({params['y_col']: y_arr,\n",
    "                        params['x_col']: ones*x,\n",
    "                        \"z\": common_dist.CD_logo_normal(y_arr/params['y_max'], *acc_models[filter_][x])})\n",
    "    dataframe = pd.concat([dataframe, df_i], axis=0)\n",
    "\n",
    "dataframe = dataframe.sort_values(by=[params['x_col'], params['y_col']])\n",
    "\n",
    "#Revert normalization of the all data\n",
    "dataframe.loc[:,'z'] = dataframe.loc[:,'z']*database['z_max'][df_filter.iloc[0]['group']]\n",
    "df_filter.loc[:,'z'] = df_filter.loc[:,'z']*database['z_max'][df_filter.iloc[0]['group']]\n",
    "\n",
    "plot_df(data_df = df_filter,\n",
    "        x_col = params['x_col'],\n",
    "        y_col = params['y_col'],\n",
    "        z_col = \"z\",\n",
    "        title = \"Original: \"+filter_, w = 10, h = 6)\n",
    "\n",
    "plot_df(data_df = dataframe,\n",
    "        x_col = params['x_col'],\n",
    "        y_col = params['y_col'],\n",
    "        z_col = \"z\",\n",
    "        title = \"Logo Normal: \"+filter_, w = 10, h = 6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f2ac25b4a6d870602abfa5d74e7d6f1ae274ba9e86645830384575c0e5c89f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
